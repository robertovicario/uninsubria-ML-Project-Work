{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression Classifier - Spiegazione Semplice**  \n",
    "La **Regressione Logistica** è un algoritmo che viene usato per **classificare** i dati in due categorie (es. \"Sì\" o \"No\", \"Spam\" o \"Non Spam\").  \n",
    "\n",
    "Funziona così:  \n",
    "1. **Analizza i dati** e calcola un punteggio basato su una formula matematica.  \n",
    "2. **Usa la funzione sigmoide** per trasformare il punteggio in una probabilità tra 0 e 1.  \n",
    "3. **Decide la classe**:  \n",
    "   - Se la probabilità è maggiore di **0.5**, assegna una classe (es. \"Spam\").  \n",
    "   - Se è minore di **0.5**, assegna l'altra classe (es. \"Non Spam\").  \n",
    "\n",
    "---\n",
    "\n",
    "### **Iperparametri Fondamentali**  \n",
    "1. **Coefficiente di Regolarizzazione (\\(\\lambda\\))**  \n",
    "   - Evita che il modello si adatti troppo ai dati di addestramento (**overfitting**).  \n",
    "   - Valori comuni: **L1 (Lasso)** o **L2 (Ridge)**.  \n",
    "\n",
    "2. **Tasso di Apprendimento (\\(\\alpha\\))**  \n",
    "   - Controlla **quanto velocemente il modello aggiorna i suoi pesi**.  \n",
    "   - Un valore troppo alto causa instabilità, uno troppo basso rende l’allenamento lento.  \n",
    "\n",
    "3. **Numero di Iterazioni**  \n",
    "   - Indica **quante volte** il modello aggiorna i pesi per migliorare la classificazione.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Dimostrazione Matematica**  \n",
    "La regressione logistica calcola una probabilità con la **funzione sigmoide**:  \n",
    "\\[\n",
    "P(Y=1 | X) = \\frac{1}{1 + e^{-(w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n)}}\n",
    "\\]\n",
    "dove:  \n",
    "- \\( X = (x_1, x_2, ..., x_n) \\) sono le caratteristiche del dato.  \n",
    "- \\( w = (w_0, w_1, ..., w_n) \\) sono i pesi del modello.  \n",
    "- \\( e \\) è la base del logaritmo naturale (≈2.718).  \n",
    "\n",
    "Per allenare il modello, si usa la **Massima Verosimiglianza**, che cerca di massimizzare:  \n",
    "\\[\n",
    "L(w) = \\prod_{i=1}^{m} P(Y_i | X_i)\n",
    "\\]\n",
    "che equivale a minimizzare la **Funzione di Costo Log-Loss**:  \n",
    "\\[\n",
    "J(w) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log P(Y_i) + (1 - y_i) \\log (1 - P(Y_i)) \\right]\n",
    "\\]\n",
    "Il modello aggiorna i pesi con **Discesa del Gradiente**:  \n",
    "\\[\n",
    "w_j := w_j - \\alpha \\frac{\\partial J}{\\partial w_j}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Esempio Pratico**  \n",
    "Immaginiamo di voler classificare email come **Spam** o **Non Spam** in base al numero di parole come \"Gratis\" e \"Offerta\".  \n",
    "\n",
    "| Email  | \"Gratis\" | \"Offerta\" | Spam (1) / Non Spam (0) |\n",
    "|--------|---------|----------|-------------------------|\n",
    "| A      | 1       | 1        | 1                       |\n",
    "| B      | 0       | 1        | 0                       |\n",
    "| C      | 1       | 0        | 1                       |\n",
    "| D      | 0       | 0        | 0                       |\n",
    "\n",
    "1. **Calcoliamo il punteggio** con una formula come:  \n",
    "   \\[\n",
    "   z = w_0 + w_1 (\\text{\"Gratis\"}) + w_2 (\\text{\"Offerta\"})\n",
    "   \\]\n",
    "2. **Applichiamo la funzione sigmoide** per ottenere una probabilità tra 0 e 1.  \n",
    "3. **Se la probabilità è > 0.5, classifichiamo l’email come Spam**, altrimenti come Non Spam.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusione**  \n",
    "La **Regressione Logistica** è semplice ed efficace per problemi di classificazione binaria, ma non funziona bene se i dati non sono separabili in modo lineare."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
